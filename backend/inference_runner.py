"""
inference_runner.py
-------------------
DeepSeek OCR åç«¯æ ¸å¿ƒæ‰§è¡Œå™¨
æ”¯æŒï¼š
- è‡ªåŠ¨è¯†åˆ« PDF / å›¾ç‰‡
- å®æ—¶è¿›åº¦å›è°ƒ
- ä¸´æ—¶è¦†ç›– config.py
- ä»»åŠ¡çŠ¶æ€ JSON æŒä¹…åŒ–
"""

import json
import os
import subprocess
import threading
from pathlib import Path
from typing import Callable, Optional, Dict, Any

from config_loader import MODEL_PATH, LOGS_DIR, DEVICE_ID
from file_manager import detect_file_type, create_result_dir, list_result_files

# æ ¸å¿ƒè„šæœ¬è·¯å¾„
PROJECT_ROOT = Path(__file__).resolve().parent
PDF_SCRIPT = PROJECT_ROOT / "run_dpsk_ocr_pdf.py"
IMAGE_SCRIPT = PROJECT_ROOT / "run_dpsk_ocr_image.py"
CONFIG_PATH = PROJECT_ROOT / "config.py"


# ====== ä»»åŠ¡çŠ¶æ€æŒä¹…åŒ– ======
def write_task_state(task_id: str, state: Dict[str, Any]):
    LOGS_DIR.mkdir(parents=True, exist_ok=True)
    state_path = LOGS_DIR / f"task_{task_id}.json"
    with open(state_path, "w", encoding="utf-8") as f:
        json.dump(state, f, indent=2, ensure_ascii=False)
    return state_path


def read_task_state(task_id: str) -> Optional[Dict[str, Any]]:
    state_path = LOGS_DIR / f"task_{task_id}.json"
    if not state_path.exists():
        return None
    try:
        with open(state_path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return None


# ====== ä¸´æ—¶å†™å…¥ config.py ======
def override_config(model_path: str, input_path: str, output_path: str, prompt: str):
    """ä¸ºæ¯ä¸ªä»»åŠ¡åŠ¨æ€ç”Ÿæˆ config.py"""
    config_lines = [
        "# Auto-generated config for DeepSeek OCR",
        "BASE_SIZE = 1024",
        "IMAGE_SIZE = 640",
        "CROP_MODE = True",
        "MIN_CROPS = 2",
        "MAX_CROPS = 6",
        "MAX_CONCURRENCY = 10",
        "NUM_WORKERS = 32",
        "PRINT_NUM_VIS_TOKENS = False",
        "SKIP_REPEAT = True",
        "",
        f"MODEL_PATH = r'{model_path}'",
        f"INPUT_PATH = r'{input_path}'",
        f"OUTPUT_PATH = r'{output_path}'",
        f'PROMPT = """{prompt}"""',
        "",
        "from transformers import AutoTokenizer",
        "TOKENIZER = AutoTokenizer.from_pretrained(MODEL_PATH, trust_remote_code=True)",
    ]
    CONFIG_PATH.write_text("\n".join(config_lines), encoding="utf-8")
    print(f"âœ… ä¸´æ—¶è¦†ç›– config.py æˆåŠŸï¼š{CONFIG_PATH}")


# ====== æ ¸å¿ƒä»»åŠ¡æ‰§è¡Œ ======
def run_ocr_task(
    input_path: str,
    task_id: str,
    on_progress: Optional[Callable[[int], None]] = None,
    prompt: str = "<image>\nFree OCR."
) -> Dict[str, Any]:
    """æ‰§è¡Œ OCR ä»»åŠ¡"""
    try:
        result_dir = create_result_dir(prefix=f"ocr_task_{task_id}")
        write_task_state(task_id, {"status": "running", "result_dir": str(result_dir)})

        file_type = detect_file_type(input_path)
        script_path = PDF_SCRIPT if file_type == "pdf" else IMAGE_SCRIPT

        override_config(MODEL_PATH, input_path, str(result_dir), prompt)

        print(f"ğŸš€ å¯åŠ¨ DeepSeek OCR ä»»åŠ¡ ({file_type.upper()})")
        print(f"ğŸ“„ ä½¿ç”¨è„šæœ¬: {script_path}")
        print(f"ğŸ“ è¾“å‡ºè·¯å¾„: {result_dir}")

        command = ["python", str(script_path)]

        # å‡†å¤‡ç¯å¢ƒå˜é‡ï¼Œç¡®ä¿ GPU è®¾å¤‡æ­£ç¡®ä¼ é€’
        env = os.environ.copy()
        env["CUDA_VISIBLE_DEVICES"] = str(DEVICE_ID)
        env["DEVICE_ID"] = str(DEVICE_ID)
        
        # å¦‚æœ CUDA ç‰ˆæœ¬æ˜¯ 11.8ï¼Œè®¾ç½® TRITON è·¯å¾„
        import torch
        if hasattr(torch, 'version') and hasattr(torch.version, 'cuda') and torch.version.cuda == '11.8':
            env["TRITON_PTXAS_PATH"] = "/usr/local/cuda-11.8/bin/ptxas"
        
        env["VLLM_USE_V1"] = "0"
        
        # éªŒè¯ GPU å¯ç”¨æ€§
        try:
            import torch
            cuda_available = torch.cuda.is_available()
            if cuda_available:
                gpu_count = torch.cuda.device_count()
                gpu_name = torch.cuda.get_device_name(int(DEVICE_ID)) if gpu_count > int(DEVICE_ID) else "Unknown"
                print(f"ğŸ”§ GPU è®¾å¤‡é…ç½®: CUDA_VISIBLE_DEVICES={DEVICE_ID}")
                print(f"âœ… CUDA å¯ç”¨: {cuda_available}, GPU æ•°é‡: {gpu_count}, GPU åç§°: {gpu_name}")
            else:
                print(f"âš ï¸ è­¦å‘Š: CUDA ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ CPUï¼ˆé€Ÿåº¦ä¼šå¾ˆæ…¢ï¼‰")
        except Exception as e:
            print(f"âš ï¸ æ— æ³•æ£€æŸ¥ GPU çŠ¶æ€: {e}")
        
        print(f"ğŸ”§ ç¯å¢ƒå˜é‡: CUDA_VISIBLE_DEVICES={env.get('CUDA_VISIBLE_DEVICES')}")

        # ä½¿ç”¨ unbuffered æ¨¡å¼ç¡®ä¿è¾“å‡ºå®æ—¶æ˜¾ç¤º
        process = subprocess.Popen(
            command,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            universal_newlines=True,
            bufsize=0,  # æ— ç¼“å†²ï¼Œå®æ—¶è¾“å‡º
            env=env,  # ä¼ é€’ç¯å¢ƒå˜é‡
        )

        progress = 0

        def _read_output():
            nonlocal progress
            for line in process.stdout:
                line = line.strip()
                if not line:  # è·³è¿‡ç©ºè¡Œ
                    continue

                # è¾“å‡ºæ‰€æœ‰æ—¥å¿—ä»¥ä¾¿è°ƒè¯•
                print(f"[OCR] {line}")

                # æ ¹æ®æ—¥å¿—å…³é”®å­—æ¨ç®—è¿›åº¦
                line_lower = line.lower()
                if "loading" in line_lower or "initializing" in line_lower:
                    progress = max(progress, 10)
                elif "pre-processed" in line_lower or "preprocessing" in line_lower:
                    progress = max(progress, 30)
                elif "generate" in line_lower or "generating" in line_lower:
                    progress = max(progress, 60)
                elif "save results" in line_lower or "saving" in line_lower:
                    progress = max(progress, 90)
                elif "result_with_boxes" in line_lower or "complete" in line_lower or "finished" in line_lower:
                    progress = 100
                elif "cuda" in line_lower or "gpu" in line_lower or "device" in line_lower:
                    # GPU ç›¸å…³æ—¥å¿—ï¼Œç‰¹åˆ«å…³æ³¨
                    print(f"ğŸ” [GPUä¿¡æ¯] {line}")

                # æ¯æ¬¡è¿›åº¦æ›´æ–°éƒ½å†™å…¥ä»»åŠ¡çŠ¶æ€æ–‡ä»¶
                write_task_state(task_id, {
                    "status": "running",
                    "result_dir": str(result_dir),
                    "progress": progress
                })

                if on_progress:
                    on_progress(progress)

        thread = threading.Thread(target=_read_output)
        thread.start()
        process.wait()
        thread.join()

        if process.returncode != 0:
            write_task_state(task_id, {"status": "error", "message": "DeepSeek OCR æ‰§è¡Œå¤±è´¥"})
            raise RuntimeError("DeepSeek OCR æ‰§è¡Œå¤±è´¥")

        files = list_result_files(result_dir)
        write_task_state(task_id, {"status": "finished", "result_dir": str(result_dir), "files": files})

        print(f"âœ… ä»»åŠ¡å®Œæˆï¼š{task_id}")
        return {"status": "finished", "task_id": task_id, "result_dir": str(result_dir), "files": files}

    except Exception as e:
        write_task_state(task_id, {"status": "error", "message": str(e)})
        print(f"âŒ ä»»åŠ¡å¼‚å¸¸ {task_id}: {e}")
        return {"status": "error", "message": str(e)}
